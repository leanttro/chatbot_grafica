import os
import psycopg2
import psycopg2.extras
from flask import Flask, jsonify, request, render_template
from dotenv import load_dotenv
from flask_cors import CORS
import json
import google.generativeai as genai
import decimal
import traceback # Para logs de erro mais detalhados

# --- CONFIGURA√á√ÉO INICIAL ---
load_dotenv() # Carrega vari√°veis do arquivo .env (DATABASE_URL, GEMINI_API_KEY)
# Servir arquivos est√°ticos (como logo.png) da pasta raiz '.'
app = Flask(__name__, template_folder='.', static_folder='.', static_url_path='')
CORS(app)

# Configura o Gemini (l√™ a chave do .env)
try:
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("‚ùå ERRO CR√çTICO: Vari√°vel de ambiente GEMINI_API_KEY n√£o encontrada no arquivo .env.")
    else:
        genai.configure(api_key=api_key)
        print("‚úÖ API Key do Gemini configurada.")
except Exception as e:
    print(f"‚ùå Erro ao configurar a API do Gemini: {e}")

# Conex√£o com o DB (l√™ a URL do .env)
def get_db_connection():
    """Cria e retorna uma conex√£o com o banco de dados PostgreSQL."""
    conn = None
    try:
        db_url = os.getenv('DATABASE_URL')
        if not db_url:
            print("‚ùå ERRO CR√çTICO: Vari√°vel de ambiente DATABASE_URL n√£o encontrada no arquivo .env.")
            raise ValueError("DATABASE_URL n√£o definida")
        conn = psycopg2.connect(db_url)
        return conn
    except Exception as e:
        print(f"‚ùå ERRO CR√çTICO: N√£o foi poss√≠vel conectar ao banco de dados: {e}")
        raise

# Helper para formatar dados (decimal, etc.)
class DecimalEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, decimal.Decimal):
            return str(obj)
        return super(DecimalEncoder, self).default(obj)
app.json_encoder = DecimalEncoder

# --- L√ìGICA DO CHATBOT (RAG com tabela 'grafica') ---

def get_grafica_data_for_bot(limit=50):
    """Busca os √∫ltimos 'limit' registros da tabela 'grafica' para o bot."""
    conn = None
    try:
        conn = get_db_connection()
        cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        cur.execute(f"SELECT id, quantidade, produto, material, impressao, largura, altura, valor_final FROM grafica ORDER BY id DESC LIMIT {limit}")
        registros_raw = cur.fetchall()
        cur.close()
        registros = [dict(row) for row in registros_raw]
        print(f"‚ÑπÔ∏è Dados do Bot: Carregados {len(registros)} registros recentes da tabela 'grafica'.")
        return registros
    except psycopg2.errors.UndefinedTable:
         print(f"‚ö†Ô∏è AVISO: A tabela 'grafica' n√£o foi encontrada. O chatbot n√£o ter√° contexto de pedidos.")
         return []
    except Exception as e:
        print(f"‚ùå ERRO ao buscar dados da tabela 'grafica' para o bot: {e}")
        traceback.print_exc()
        return []
    finally:
        if conn: conn.close()

grafica_data_context = get_grafica_data_for_bot()
grafica_json_context = json.dumps(grafica_data_context, cls=DecimalEncoder, ensure_ascii=False, separators=(',', ':'))

# --- NOVO SYSTEM PROMPT ---
SYSTEM_PROMPT = f"""
Voc√™ √© o 'GrafiBot', um assistente virtual amig√°vel e especialista da Teclabel, focado em ajudar usu√°rios a obterem *estimativas* de or√ßamento para produtos gr√°ficos.
Sua √∫nica fonte de verdade para estimativas √© a base de dados de pedidos recentes em JSON fornecida abaixo.

--- BASE DE DADOS (Pedidos Recentes - JSON) ---
{grafica_json_context}
--- FIM DA BASE DE DADOS ---

**FLUXO DE CONVERSA PARA OR√áAMENTO (SIGA ESTRITAMENTE):**

1.  **Sauda√ß√£o Amig√°vel e Apresenta√ß√£o:** Comece sempre com algo como: "Ol√°! üëã Sou o GrafiBot, seu assistente virtual da Teclabel. Estou aqui para ajudar a estimar o valor do seu pr√≥ximo pedido ou consultar registros recentes. Como posso te ajudar hoje?"
2.  **Identifique a Inten√ß√£o (Or√ßamento):** Se o usu√°rio expressar interesse em pre√ßo, or√ßamento, cota√ß√£o ou valor:
    * **Pergunte o Essencial (1¬™ pergunta):** "Legal! Para come√ßarmos, me diga qual **produto** voc√™ tem em mente e a **quantidade** aproximada."
    * **Colete Detalhes Essenciais (Perguntas seguintes, UMA DE CADA VEZ):** Baseado na resposta, pergunte educadamente pelos detalhes CHAVE que voc√™ v√™ na BASE DE DADOS (Material, Impress√£o, Tamanho). Exemplos:
        * "Entendido. E qual **material** voc√™ est√° pensando para essas etiquetas?"
        * "Perfeito. E como seria a **impress√£o**? (Ex: 4x0 cores, 1x0 cor, digital...)"
        * "Anotado! Qual o **tamanho** aproximado que voc√™ precisa (Largura x Altura em cm)?"
    * **Continue perguntando** at√© ter pelo menos: Produto, Quantidade, Material e Impress√£o. O tamanho √© bom ter, mas opcional se n√£o souber.
3.  **Confirme os Dados Coletados:** Antes de prosseguir, recapitule de forma clara: "Ok, vamos confirmar: Voc√™ precisa de [Quantidade] [Produto] em [Material], com impress√£o [Impress√£o] e tamanho aproximado [LxA cm, se informado]. √â isso mesmo?"
4.  **Busque e Forne√ßa a ESTIMATIVA (SEMPRE):** Se o usu√°rio confirmar:
    * Procure na BASE DE DADOS por 1 ou 2 pedidos **o mais similares poss√≠vel** (mesmo produto/material, quantidade pr√≥xima).
    * **APRESENTE A ESTIMATIVA:** "Com base em pedidos recentes parecidos que encontrei aqui, uma estimativa para o seu pedido seria **em torno de R$ XXX,XX**."
    * **JUSTIFIQUE COM EXEMPLO:** "Para voc√™ ter uma ideia, encontrei o pedido ID [ID do Exemplo], que foram [Qtd Exemplo] [Produto Exemplo] em [Material Exemplo], e o valor final ficou em R$ [Valor Exemplo]." (Use apenas UM exemplo claro).
    * **REFORCE QUE √â ESTIMATIVA:** Conclua SEMPRE com: "**Lembre-se: este √© apenas um valor estimado** baseado em pedidos anteriores, ok? Para um or√ßamento exato e formal, por favor, preencha o formul√°rio de cadastro na p√°gina."
5.  **Se N√£o Achar Similar:** Seja honesto: "Hmm, n√£o encontrei pedidos recentes muito parecidos com essas especifica√ß√µes na minha base para dar uma estimativa confi√°vel ü§î. Recomendo preencher o formul√°rio na p√°gina para receber um or√ßamento preciso da nossa equipe."

**OUTRAS REGRAS:**

* **Consulta de Vendas:** Se o usu√°rio perguntar sobre vendas/pedidos recentes, liste os 3-5 exemplos mais recentes da BASE DE DADOS de forma resumida (ID, Produto, Qtd, Valor).
* **N√ÉO ALUCINE:** Jamais invente pre√ßos, produtos, materiais ou caracter√≠sticas. Se n√£o est√° na base, n√£o existe para voc√™.
* **SEJA CONVERSACIONAL e PACIENTE:** Use emojis leves (üëã, üëç, ü§î, ‚úÖ), seja educado e guie o usu√°rio passo a passo.
* **FOCO NA GR√ÅFICA:** Responda apenas sobre or√ßamentos e pedidos da gr√°fica. Recuse educadamente outros assuntos.
"""
# --- FIM DO NOVO SYSTEM PROMPT ---


# Inicializa o Modelo e a Sess√£o de Chat
model = None
chat_session = None
try:
    if api_key:
        model = genai.GenerativeModel('gemini-flash-latest')
        chat_session = model.start_chat(
            history=[
                {"role": "user", "parts": [SYSTEM_PROMPT]},
                # Nova Mensagem Inicial do Modelo (mais amig√°vel)
                {"role": "model", "parts": ["Ol√°! üëã Sou o GrafiBot, seu assistente virtual da Teclabel. Estou aqui para ajudar a estimar o valor do seu pr√≥ximo pedido ou consultar registros recentes. Como posso te ajudar hoje?"]}
            ]
        )
        print("‚úÖ Modelo Gemini ('gemini-flash-latest') inicializado com o NOVO contexto.")
    else:
        print("‚ö†Ô∏è AVISO: API Key do Gemini n√£o carregada. O chatbot n√£o funcionar√°.")

except Exception as e:
    print(f"‚ùå ERRO CR√çTICO ao inicializar o GenerativeModel: {e}")
    traceback.print_exc()

# --- ROTAS DA APLICA√á√ÉO ---

@app.route('/')
def index():
    """Serve a p√°gina principal."""
    return render_template('index.html')

@app.route('/api/chat', methods=['POST'])
def handle_chat():
    """Recebe a mensagem do usu√°rio e retorna a resposta do Gemini."""
    if not model or not chat_session:
        print("‚ùå Erro na Rota /api/chat: Sess√£o do Gemini n√£o inicializada.")
        return jsonify({'error': 'Servi√ßo de chat indispon√≠vel no momento.'}), 503

    try:
        data = request.json
        user_message = data.get('message')

        if not user_message:
            return jsonify({'error': 'Mensagem n√£o pode ser vazia.'}), 400

        print(f"üí¨ Mensagem do Usu√°rio: {user_message}") # Log da mensagem recebida

        # Envia a mensagem para o Gemini
        response = chat_session.send_message(
            user_message,
            generation_config=genai.types.GenerationConfig(temperature=0.7), # Um pouco de criatividade
            safety_settings={'HATE': 'BLOCK_NONE', 'HARASSMENT': 'BLOCK_NONE',
                             'SEXUAL' : 'BLOCK_NONE', 'DANGEROUS' : 'BLOCK_NONE'}
        )

        # Log curto da resposta antes de enviar
        print(f"ü§ñ Resposta do Bot: {response.text[:100]}...")
        return jsonify({'reply': response.text})

    except genai.types.generation_types.StopCandidateException as stop_ex:
        print(f"‚ö†Ô∏è API BLOQUEOU a resposta por seguran√ßa: {stop_ex}")
        return jsonify({'reply': "Desculpe, n√£o posso gerar uma resposta para essa solicita√ß√£o espec√≠fica. Posso ajudar com or√ßamentos ou consulta de pedidos?"})
    except Exception as e:
        print(f"‚ùå Erro ao chamar a API do Gemini: {e}")
        traceback.print_exc()
        return jsonify({'error': 'Ocorreu um erro ao processar sua mensagem com a IA.'}), 503

# Rota para registrar o pedido na tabela 'grafica'
@app.route('/api/registrar_pedido', methods=['POST'])
def registrar_pedido():
    """Recebe dados do formul√°rio HTML e insere na tabela 'grafica'."""
    dados = request.json
    conn = None
    print(f"‚ÑπÔ∏è Recebido POST em /api/registrar_pedido: {dados}")

    if not dados or 'quantidade' not in dados or 'produto' not in dados or 'valorFinal' not in dados:
         print("‚ùå Erro em /api/registrar_pedido: Dados incompletos recebidos.")
         return jsonify({'error': 'Dados incompletos para registrar o pedido.'}), 400

    try:
        conn = get_db_connection()
        cur = conn.cursor()

        sql_insert = """
        INSERT INTO grafica (
            QUANTIDADE, PRODUTO, MATERIAL, IMPRESSAO, LARGURA, ALTURA,
            TIPO_DE_CORTE, ACABAMENTO, EXTRA, VALOR_FINAL
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);
        """
        valores = (
            dados.get('quantidade'), dados.get('produto'), dados.get('material'),
            dados.get('impressao'), dados.get('largura') or None, dados.get('altura') or None,
            dados.get('tipoCorte') or None, dados.get('acabamento'), dados.get('extra') or None,
            dados.get('valorFinal')
        )

        cur.execute(sql_insert, valores)
        conn.commit()
        cur.close()
        print("‚úÖ Pedido registrado com sucesso na tabela 'grafica'.")

        # Recarrega o contexto do bot AP√ìS salvar o novo pedido
        global grafica_data_context, grafica_json_context, SYSTEM_PROMPT, chat_session
        print("üîÑ Recarregando contexto do bot ap√≥s novo pedido...")
        grafica_data_context = get_grafica_data_for_bot() # Busca os dados mais recentes
        grafica_json_context = json.dumps(grafica_data_context, cls=DecimalEncoder, ensure_ascii=False, separators=(',', ':'))

        # ATUALIZA O SYSTEM_PROMPT com os novos dados
        SYSTEM_PROMPT = f"""
        Voc√™ √© o 'GrafiBot', um assistente virtual amig√°vel... (COLE O NOVO PROMPT COMPLETO AQUI)...
        --- BASE DE DADOS (Pedidos Recentes - JSON) ---
        {grafica_json_context}
        --- FIM DA BASE DE DADOS ---
        ... (Resto das regras) ...
        """

        # Reinicia a sess√£o de chat com o prompt atualizado
        if model:
             # Guarda o hist√≥rico antigo (opcional, pode ficar confuso)
             # old_history = chat_session.history if chat_session else []

             chat_session = model.start_chat(
                history=[
                    {"role": "user", "parts": [SYSTEM_PROMPT]},
                    {"role": "model", "parts": ["Entendido. Sou o GrafiBot. Base de pedidos atualizada com o √∫ltimo registro. Pronto para ajudar."]}
                    # Pode tentar adicionar o hist√≥rico antigo aqui se quiser manter a conversa:
                    # *old_history[2:] # Pula os prompts iniciais antigos
                ]
            )
             print("‚úÖ Contexto do bot atualizado dinamicamente com o novo pedido.")
        else:
             print("‚ö†Ô∏è Bot n√£o inicializado, n√£o foi poss√≠vel atualizar contexto.")

        return jsonify({'success': 'Pedido registrado! O chatbot j√° est√° ciente deste novo pedido.'}), 201

    except psycopg2.errors.UndefinedTable:
        print(f"‚ùå ERRO em /api/registrar_pedido: A tabela 'grafica' n√£o existe.")
        return jsonify({'error': "Erro interno: Tabela 'grafica' n√£o encontrada."}), 500
    except psycopg2.Error as db_err:
        print(f"‚ùå ERRO de Banco de Dados em /api/registrar_pedido: {db_err}")
        traceback.print_exc()
        if conn: conn.rollback()
        return jsonify({'error': 'Erro ao salvar o pedido no banco de dados.'}), 500
    except Exception as e:
        print(f"‚ùå ERRO inesperado em /api/registrar_pedido: {e}")
        traceback.print_exc()
        if conn: conn.rollback()
        return jsonify({'error': 'Erro interno do servidor ao registrar pedido.'}), 500
    finally:
        if conn: conn.close()

# --- Execu√ß√£o do App ---
if __name__ == '__main__':
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port, debug=False, use_reloader=False)

